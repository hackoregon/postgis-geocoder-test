---
title: "Hack Oregon Transportation Data Cleaning / Geocoding"
output:
  github_document: default
  html_notebook: default
---

## Source data
The original source data came from the City of Portland. We received two PDFs for "grind and pave" projects, which appear to contain identical tables. We converted them manually to the CSV files here using [Tabula](http://tabula.technology/). If we receive more PDFs, Tabula has a command-line option that can be scripted from most higher-level languages, including both Python and R.

The remainder of the files were received as comma-separated-value (CSV) files. The process of uploading them to Google Drive and downloading them again converted them to Microsoft Excel(.xlsx) format. We converted them back to the CSV files here manually using LibreOffice. Again, if we receive more such files we can automate the processing.

## Tidying the data
Once converted to CSV, inspection shows that the data are in multiple formats. The geocoding process requires a tidy set of inputs, so we define a tidy format and populate it with data from the files.

### Inputs
First, we import the CSV files to individual data frames.

```{r}
if(!require(readr)) install.packages("readr")
library(readr)
Pavement_Moratorium <- read_csv(
  "/home/Projects/postgis-geocoder-test/Data/Pavement Moratorium.csv",
  col_types = cols(
    `Moratorium End Date` = col_date(format = "%m/%d/%Y"),
    OBJECTID = col_character(), 
    `Treatment Date` = col_date(format = "%m/%d/%Y")))
print(Pavement_Moratorium)

Planned_Fog_Seal <- read_csv(
  "/home/Projects/postgis-geocoder-test/Data/Planned Fog Seal.csv",
  col_types = cols(
    OBJECTID = col_character()))
print(Planned_Fog_Seal)

Planned_Paving <- read_csv(
  "/home/Projects/postgis-geocoder-test/Data/Planned Paving.csv",
  col_types = cols(OBJECTID = col_character()))
print(Planned_Paving)

tabula_G_P_Schedule_as_of_1_5_2017 <- read_csv(
  "/home/Projects/postgis-geocoder-test/Data/tabula-G_P Schedule as of 1-5-2017.csv",
  col_types = cols(Start = col_character()))
print(tabula_G_P_Schedule_as_of_1_5_2017)

```
### Column names
Note that the columns defined are different for the files. The columns we need to geocode the intersections are the `Street`, `From Street` and `To Street`. Moreover, the "Grind and Pave" data has those columns combined in a single `Task Name` column, and we want "database friendly" column names - all lower case letters with underscores instead of spaces for separators. So we use `dplyr` to make new tidy data frames and save them to new CSV files. We will tag the rows with a source file name and source file row number for traceability.

### Parsers

#### Grind and Pave
This is the most complicated parser, since the `Street`, `From Street` and `To Street` fields are all given in a single column. There are also two extraneous rows that need to be removed.

```{r}
if(!require(dplyr)) install.packages("dplyr")
library(dplyr)
if(!require(tibble)) install.packages("tibble")
library(tibble)
grind_and_pave <- tabula_G_P_Schedule_as_of_1_5_2017 %>%
  mutate(source_file_name = "G_P Schedule as of 1-5-2017.pdf") %>%
  rownames_to_column(var = "source_row_number") %>%
  filter(!is.na(`Task Name`), `Task Name` != "FY 17/18") %>%
  select(source_file_name, source_row_number, `Task Name`) %>%
  mutate(
    street = sub(":.*$", "", `Task Name`),
    from_street = gsub("\r", " ", `Task Name`) %>%
      sub("^.*:", "", .) %>%
      sub(" to .*$", "", .),
    to_street = gsub("\r", " ", `Task Name`) %>%
      sub("^.* to ", "", .)) %>%
  select(-`Task Name`)
```

#### Pavement moratorium
This one's easier - the only non-tidy feature is that some of the `Street` entries have a " Base-Repair" or similar tacked onto the end.

```{r}
pavement_moratorium <- Pavement_Moratorium %>%
  mutate(
    source_file_name = "Pavement Moratorium.csv",
    street = sub("Base.*$", "", Street) %>% sub("-$", "", .)) %>%
  rownames_to_column(var = "source_row_number") %>%
  select(
    source_file_name, 
    source_row_number, 
    street, 
    from_street = `From Street`,
    to_street = `To Street`)
```

#### Planned fog seal
```{r}
planned_fog_seal <- Planned_Fog_Seal %>%
  mutate(source_file_name = "Planned Fog Seal.csv") %>%
  rownames_to_column(var = "source_row_number") %>%
  select(
    source_file_name, 
    source_row_number, 
    street = Street, 
    from_street = `From Street`,
    to_street = `To Street`)
```

#### Planned paving
```{r}
planned_paving <- Planned_Paving %>%
  mutate(source_file_name = "Planned Paving.csv") %>%
  rownames_to_column(var = "source_row_number") %>%
  select(
    source_file_name, 
    source_row_number, 
    street = Street, 
    from_street = `From Street`,
    to_street = `To Street`)
```

## Combine the tidied files and ship them off to the PostGIS geocoder
```{r}
tidy_geocoder_input <- bind_rows(
  grind_and_pave,
  pavement_moratorium,
  planned_fog_seal,
  planned_paving)
tidy_geocoder_input$from_street[is.na(tidy_geocoder_input$from_street)] <- ""
tidy_geocoder_input$to_street[is.na(tidy_geocoder_input$to_street)] <- ""
write_csv(tidy_geocoder_input, path = "tidy_geocoder_input.csv")
```

